# -*- coding: utf-8 -*-
"""RAGAS-LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XtIx5bJThSiF5FI3wTqIl7NgMk_X4Tnr

# ðŸ§  RAGASâ€‘Enabled LangChainâ€‘Groq Chat Evaluation

This notebook shows how to:
1. **Engage in a multi-turn chat** using LangChain + Groq  
2. **Capture** (question, retrieved context, GPT answer) tuples  
3. **Evaluate** them with RAGAS using key metrics:  
   - Context Recall/Precision  
   - Faithfulness  
   - Answer Relevance / Correctness

User â†’ LangChain + Groq â†’ (Answer + Context Chunks stored)
       â†“
 Collect Q/A/C tuples â†’ Format into RAGAS Dataset â†’ evaluate()
 â†’ Metrics: context_recall, faithfulness, answer_relevancy â€¦
"""

# Cell 1: Install dependencies
!pip install -q langchain langchain-groq ragas langchain-openai

# Cell 2: Imports & Setup
from langchain_groq import ChatGroq
from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain.memory import ConversationBufferMemory
from IPython.display import Markdown, display

# RAGAS imports
from ragas import SingleTurnSample, EvaluationDataset, evaluate
from ragas.metrics import LLMContextRecall, ContextPrecision, Faithfulness, AnswerRelevancy, FactualCorrectness
from ragas.llms import LangchainLLMWrapper

# Cell 3: Initialize LLMs for chat and for RAGAS evaluation
from google.colab import userdata
llm = ChatGroq(model="llama-3.3-70b-versatile", api_key=userdata.get('GROQ_API_KEY'), temperature=0)
llm_eval = LangchainLLMWrapper(llm)  # reuse same LLM as evaluator via wrapper

from langchain_openai import ChatOpenAI
from ragas.llms import LangchainLLMWrapper
import os
os.environ["OPENAI_API_KEY"] = userdata.get('OPENAI_API_KEY_')
llm_eval = LangchainLLMWrapper(
    ChatOpenAI(model="gpt-4o-mini", temperature=0.2, api_key=os.environ["OPENAI_API_KEY"])  # or gpt-3.5-turbo
)

# Cell 4: Build Chat Pipeline
system_msg = SystemMessagePromptTemplate.from_template("You are a helpful assistant.")
human_msg = HumanMessagePromptTemplate.from_template("{input}")
chat_prompt = ChatPromptTemplate.from_messages([system_msg, MessagesPlaceholder("history"), human_msg])

memory = ConversationBufferMemory(return_messages=True)
chat_chain = chat_prompt | llm
chatbot = RunnableWithMessageHistory(chat_chain, lambda _: memory.chat_memory,
                                     input_messages_key="input", history_messages_key="history")

# Cell 5: Run chat and collect data
session_id = "session1"
records = []

user_inputs = ["What is the moon made of?", "How does gravity on the moon differ from Earth?"]
for user in user_inputs:
    resp = chatbot.invoke({"input": user}, config={"configurable": {"session_id": session_id}})
    answer = resp.content
    contexts = []  # if using retrieval pipeline, collect contexts here
    # For demo, mark empty context or custom retrieval
    records.append({"question": user, "answer": answer, "contexts": contexts})
    display(Markdown(f"**User:** {user}\n\n**Assistant:** {answer}"))

samples = [
    {
        "user_input": r["question"],
        "retrieved_contexts": r["contexts"],  # list of context strings
        "response": r["answer"],              # RAGAS expects "response" now
        # No reference since you're not using ground truth
    }
    for r in records
]
print(samples)
from ragas.evaluation import EvaluationDataset
dataset = EvaluationDataset.from_dict(samples)

from ragas.metrics import LLMContextRecall, ContextPrecision, Faithfulness, AnswerRelevancy, FactualCorrectness

metrics = [
    # FactualCorrectness(),
    # LLMContextRecall(),
    # ContextPrecision(),
    Faithfulness(),
    AnswerRelevancy()
]

# Cell 7: Run RAGAS evaluation
# metrics = [LLMContextRecall(), ContextPrecision(), Faithfulness(), AnswerRelevancy(), FactualCorrectness()]

result = evaluate(
    dataset,
    metrics=metrics,
    llm=llm_eval,
    show_progress=True
)

print(result)



